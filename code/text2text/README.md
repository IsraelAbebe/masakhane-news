# [AfriTeVa: Extending “Small Data” Pretraining Approaches to Sequence-to-Sequence Models](https://github.com/castorini/afriteva)











```

@inproceedings{jude-ogundepo-etal-2022-afriteva,
    title = "{A}fri{T}e{VA}: Extending ?Small Data? Pretraining Approaches to Sequence-to-Sequence Models",
    author = "Jude Ogundepo, Odunayo  and
      Oladipo, Akintunde  and
      Adeyemi, Mofetoluwa  and
      Ogueji, Kelechi  and
      Lin, Jimmy",
    booktitle = "Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing",
    month = jul,
    year = "2022",
    address = "Hybrid",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.deeplo-1.14",
    doi = "10.18653/v1/2022.deeplo-1.14",
    pages = "126--135",
    abstract = "t",
}

```

